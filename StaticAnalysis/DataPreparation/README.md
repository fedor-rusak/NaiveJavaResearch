# Data preparation

So I need to get useful information for analysis of dependencies between huge piles of java classes.

Input data is generated by java application (from ClassParsing) and results in folder structure similar to original one but with class.json files which keep constant pool data of corresponding class.

So first is *prepare* which transforms tree of JSON files with constant data to a one file moduleName and array of objects describing each class.json file. Each object contains thisClassName, superClassName and dependency classes.

Second step is *compress*. Combining all objects from prepare-script into one JSON object with three properties: moduleName, provided (classes), dependencies.

Third step is *linking* which processes multiple files from compress-script to generate one JSON file with array of module-linkage-state information. So each module-linkage-state has *moduleName*, *required* (modules) which contains moduleNames used for resolving dependencies, *linked* (classes) where className points to id from *required*, *unlinked* (classes) which still miss corresponding moduleName, *provided* (classes) classes which are presented in module. It will also make a mini-version where provided and linked components are omitted.

One last touch is to save minified version of data with additional javascript syntax so that we can call this data as from our html-page for visualization.